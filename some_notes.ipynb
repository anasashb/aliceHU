{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [A Review of Feature Selection and Its Methods](https://sciendo.com/article/10.2478/cait-2019-0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Types of Feature Selection Methods:\n",
    "\n",
    "### Filter\n",
    "- Features are selected based on statistical measures: **information gain, $\\chi^2$, fisher, pearson, etc**\n",
    "- Independent of learning algorithm - in other words, model-agnostic\n",
    "- Less computationally expensive\n",
    "### Wrapper\n",
    "- Features are selected based on learner's results\n",
    "- More computationally expensive, but more accurate\n",
    "- **Recursive Feature Elimination, Sequential Feature Selection, Genetic Algorithms**\n",
    "### Embedded\n",
    "- Ensemble learning methods such as Random Forests\n",
    "\n",
    "- - -\n",
    "\n",
    "## Three Types of Search Directions:\n",
    "\n",
    "### Forward (Sequential)\n",
    "- Begin with empty set, add features in each iteration\n",
    "\n",
    "### Backward (Sequential)\n",
    "- Begin with full set, remove features in each iteration\n",
    "\n",
    "### Random (Random)\n",
    "- Build feature subset by adding and removing features iteratively\n",
    "\n",
    "- - -\n",
    "\n",
    "## $P$ vs $NP$:\n",
    "\n",
    "The forward and backward types of sequential search and random search algorithms are proposed as opposed to exhaustive, greedy search that would try out all $2^n$ combinations for $n$ amount of features, an NP-hard problem.\n",
    "\n",
    "They do, however have a drawback in that once a feature is eliminated, it will no longer be considered in any shape or form in other iterations, which leads to what is called a \"nesting effect.\"\n",
    "\n",
    "- - -\n",
    "\n",
    "## Stopping Criteria:\n",
    "\n",
    "- Pre-defined No. of features\n",
    "- Pre-defined No. of iterations\n",
    "- Percentage of advancement over two successive iteration steps\n",
    "- Based on a specific evaluation function.\n",
    "\n",
    "- - -\n",
    "\n",
    "## *For our purposes*\n",
    "We will be dealing with **wrapper methods** as model results are essential for agreeability. Since predictions have to be made at every iteration to measure agreeability, going on to select or de-select features with suboptimal (filter) methods over wrapper methods would lack common sense.\n",
    "\n",
    "We can go ahead and consider:\n",
    "- Sequential Forward Selection (SFS)\n",
    "- Sequential Backward Elimination (SBE)\n",
    "- Plus-$l$-Take-Away-$r$ ($l-r$) Algorithm\n",
    "\n",
    "## Informal Pseudo Codes\n",
    "\n",
    "### SBE - for optimizing\n",
    "\n",
    "1. Initialize:\n",
    "   - Set `features` as the full set of features.<br>\n",
    "   - Define `model`, a machine learning model.<br>\n",
    "   - Define `performance_metric`, a metric to evaluate the model (e.g., accuracy, MSE).<br>\n",
    "   - Set `min_features`, the minimum number of features to retain<br>\n",
    "\n",
    "2. While `features` $>$ `min_features`:<br>\n",
    "   a. Initialize `best_score` to a very low value (e.g., -inf for accuracy, inf for MSE).<br>\n",
    "   b. For each feature `f` in `features`:<br>\n",
    "      i. Create a temporary feature set `temp_features` by removing `f` from `features`.<br>\n",
    "      ii. Train `model` using `temp_features`.<br>\n",
    "      iii. Evaluate the performance of `model` using `performance_metric`.<br>\n",
    "      iv. If the performance is better than `best_score`:<br>\n",
    "          - Update `best_score` with the new performance.<br>\n",
    "          - Record `f` as the `feature_to_remove`.<br>\n",
    "   c. Remove `feature_to_remove` from `features`.<br>\n",
    "\n",
    "3. The final set of features in `features` is the selected subset.<br>\n",
    "\n",
    "To amend this algorithm to incorporate inter-rater reliability measures, set `min_features` to $0$ to fully exhaust.\n",
    "\n",
    "SBE and ($l-r$) not in progress yet.\n",
    "\n",
    "\n",
    "\n",
    "Some sources:\n",
    "\n",
    "https://www.islab.ulsan.ac.kr/files/announcement/312/Orthogonal%20Forward%20Selection%20and%20Backward%20Elimination.pdf\n",
    "\n",
    "https://sciendo.com/article/10.2478/cait-2019-0001\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/B9780444818928500407"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
